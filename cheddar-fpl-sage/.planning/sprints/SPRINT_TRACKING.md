## Sprint Tracking (Authoritative)
* **Phase 1:** pull/store FPL data reliably (weekly DB snapshots)
* **Phase 2:** build â€œweekly model inputsâ€ from that DB (repeatable, deterministic)
* **Phase 3:** run the model + decisions off the weekly DB (no live API dependency)
* **Phase 4:** only then tighten automation/authority

This aligns with your architecture invariants: contracts at boundaries, no silent drift, no decisions on incomplete projections.

---

# SPRINT_TRACKING.md (Rewrite) â€” Data First, Then Models

## North Star

**Stop running the decision engine against live, timing-sensitive API truth.**
Start running the engine against **weekly updated, versioned data snapshots**.

**Rule:** If it canâ€™t be reproduced from stored artifacts, it didnâ€™t happen.

---

## Phase 0 â€” Define the Data Contract (1 day)

### Goal

A single canonical schema for the stored â€œweekly snapshot,â€ with provenance.

### Deliverables

* `db/schema.md` (or `docs/data_schema.md`): tables/fields + meaning
* `db/snapshot_manifest.json` contract:

  * `season`
  * `gw`
  * `snapshot_ts`
  * `sources` (fpl_api, projections, injuries)
  * `hashes` for each artifact
  * `collection_status` per source: `OK | PARTIAL | FAILED`

### Acceptance tests

* A snapshot is considered â€œVALIDâ€ only if:

  * `bootstrap-static` stored + hash
  * `fixtures` stored + hash
  * `events` / GW resolution stored (no `season=unknown`)
* No downstream step is allowed to infer missing pieces.

---

## Phase 1 â€” Build the Storage Layer (DB-first): âœ… COMPLETE

**Date Completed:** 2026-01-02  
**Status:** All acceptance tests passing (6/6 âœ…)

### Goal

Persist weekly data in a database so the rest of the system never depends on live API.

### Decision: DB Format

**Chosen: SQLite** (simple, portable, perfect for versioned snapshot storage)

### Deliverables

#### `src/storage/fpl_db.py` (470 lines, fully functional)

**Class: `FPLDatabase`**
- Context manager pattern: `with FPLDatabase(db_path) as db:`
- `init_db()` â€” Creates 5 SQLite tables with proper constraints
- `compute_sha256(file_path)` â€” Static method for file hashing
- `upsert_bootstrap(snapshot_id, status, json_path, computed_hash)` â€” Record bootstrap artifact
- `upsert_fixtures(snapshot_id, status, json_path, computed_hash)` â€” Record fixtures artifact
- `upsert_events(snapshot_id, status, json_path, computed_hash)` â€” Record events artifact
- `upsert_team_picks(snapshot_id, status, json_path, computed_hash)` â€” Record team_picks artifact (optional)
- `write_manifest(snapshot_id, season, gw, manifest_dict)` â€” Store snapshot metadata to DB
- `validate_snapshot(snapshot_id, verify_hashes=True)` â€” Comprehensive validation
- `get_snapshot_manifest(snapshot_id)` â€” Retrieve stored manifest by ID
- `list_snapshots(season=None)` â€” Query snapshots, optionally filtered

**DB Schema (5 tables):**
```
snapshots
  â”œâ”€ snapshot_id (PK)
  â”œâ”€ season, gw
  â”œâ”€ snapshot_ts
  â”œâ”€ manifest_json
  â””â”€ validation_status

bootstrap_raw
  â”œâ”€ snapshot_id (FK)
  â”œâ”€ json_path (nullable for non-OK status)
  â”œâ”€ sha256 (nullable for non-OK status)
  â””â”€ status (OK|FAILED|UNAVAILABLE_404)

fixtures_raw
  â””â”€ (same as bootstrap_raw)

events_raw
  â””â”€ (same as bootstrap_raw)

team_picks_raw
  â””â”€ (same as bootstrap_raw, can be entirely NULL/UNAVAILABLE_404)
```

#### `scripts/test_phase1.py` (240 lines, 6 tests)

**Test Suite: `TestPhase1StorageLayer`**

| Test | Scenario | Status |
|------|----------|--------|
| `test_a1_snapshot_roundtrip_write_read` | Write snapshot â†’ close DB â†’ reopen â†’ query returns same data + hashes | âœ… PASS |
| `test_a2_hash_integrity_check` | Recorded hash matches computed hash | âœ… PASS |
| `test_a3_corrupt_json_fails_validation` | Corrupt JSON file fails hash validation | âœ… PASS |
| `test_a4_missing_required_source_fails_validation` | Snapshot without bootstrap fails validation | âœ… PASS |
| `test_a5_team_picks_optional` | Snapshot valid even with team_picks UNAVAILABLE_404 | âœ… PASS |
| `test_a6_failed_source_fails_validation` | Snapshot with FAILED source fails validation | âœ… PASS |

**Test Results:**
```
6 PASSED in 0.46s
- test_a1_snapshot_roundtrip_write_read âœ…
- test_a2_hash_integrity_check âœ…
- test_a3_corrupt_json_fails_validation âœ…
- test_a4_missing_required_source_fails_validation âœ…
- test_a5_team_picks_optional âœ…
- test_a6_failed_source_fails_validation âœ…
```

### Validation Logic

A snapshot is **VALID** only if:
- `bootstrap_raw`, `fixtures_raw`, `events_raw` all have status=`OK`
- All `OK` sources have valid SHA256 hashes
- All `OK` source files exist and hashes match stored values
- `team_picks_raw` can be `UNAVAILABLE_404` (optional)
- No "unknown" season/gw in manifest

**Failure Conditions:**
- Any `FAILED` source â†’ snapshot invalid
- Any hash mismatch â†’ snapshot invalid
- Missing required source â†’ snapshot invalid
- Corrupt JSON file â†’ fails hash validation

### Key Features Implemented

âœ… Atomic writes with commit after each operation  
âœ… UNIQUE constraints prevent duplicate artifacts per snapshot  
âœ… Foreign keys link artifacts to snapshots  
âœ… Full provenance tracking: path, hash, status, timestamp  
âœ… SHA256 hash computation at write time for integrity verification  
âœ… Hash re-computation during validation for corruption detection  
âœ… Optional team_picks handling (can be NULL or UNAVAILABLE_404)  

### Integration Points

- `weekly_bundle_collector.py` will call `db.upsert_*()` after writing each JSON
- `simple_fpl_collector.py` will record collection status (OK, FAILED, UNAVAILABLE_404)
- Downstream phases query snapshots via `get_snapshot_manifest()` instead of live API

---

## Phase 2 â€” STAGE A: Collect All FPL Metrics: âœ… COMPLETE

**Date Completed:** 2026-01-02  
**Status:** All acceptance tests passing (6/6 âœ…)

**Operating Rule:** *Only the collector calls the FPL API. The model runs from `snapshot_id` only.*

### Goal

Fetch all required FPL data into one reproducible snapshot bundle, with explicit status tracking and reproducibility.

### What "All Metrics" Means (FPL-only)

| Bucket | Endpoint | Required | Notes |
|--------|----------|----------|-------|
| Global state | `/bootstrap-static/` | âœ… | Players, teams, prices, injuries, events, ownership |
| Fixtures | `/fixtures/` | âœ… | Schedule, results, team info |
| Gameweek live stats | `/event/{gw}/live` | ğŸ”„ | Best-effort; populate once GW starts |
| Team meta | `/entry/{team_id}` | âœ… | Rank, bank, value, transfers |
| Team picks | `/entry/{team_id}/event/{gw}/picks` | âš ï¸ | Best-effort; store `UNAVAILABLE_404` |
| Team history | `/entry/{team_id}/history` | âœ… | Chip usage audit |
| Transfers | `/entry/{team_id}/transfers` | âš ï¸ | Optional; fallback to manual input |

### Deliverables

#### `src/collectors/weekly_snapshot_collector.py` (580 lines, fully functional)

**Class: `WeeklySnapshotCollector`**
- Async context manager: `async with WeeklySnapshotCollector() as collector:`
- `collect_snapshot(season, gw_target, team_ids)` â†’ returns snapshot_id
- Full endpoint coverage:
  - âœ… Bootstrap (required)
  - âœ… Fixtures (required)
  - âœ… Events (required, derived from bootstrap)
  - âœ… Entry/{team_id} (required for each team)
  - âœ… Entry/{team_id}/history (required for each team, chip usage)
  - âœ… Entry/{team_id}/event/{gw}/picks (best-effort)
  - âœ… Event/{gw}/live (best-effort, GW dependent)

**Status Tracking:**
- `OK` â€” collected, stored, hash computed
- `UNAVAILABLE_404` â€” endpoint returned 404 (expected for future GWs)
- `FAILED_TIMEOUT` â€” connection timeout
- `FAILED_PARSE` â€” JSON parse error
- `FAILED` â€” 5xx or other unexpected error

**Hard Rules Enforced:**
- GW resolved from bootstrap.events.is_current (never "unknown")
- If bootstrap OR fixtures fails â†’ raises ValueError (snapshot invalid)
- Team picks can be UNAVAILABLE_404 (optional)
- Event/live is best-effort only
- All artifacts written to both JSON files and SQLite DB

**Snapshot ID Format:** `{season}_{gw}_{YYYYMMDD}_{HHMMSS}`  
Example: `2024_21_20250102_100000`

#### `scripts/test_phase2_collector.py` (340 lines, 6 tests)

**Test Suite: `TestPhase2StorageLayer`**

| Test | Scenario | Status |
|------|----------|--------|
| `test_p2_a1` | Collect bootstrap + fixtures â†’ valid snapshot | âœ… PASS |
| `test_p2_a2` | Picks 404 â†’ snapshot still valid + manifest records UNAVAILABLE_404 | âœ… PASS |
| `test_p2_a3` | Bootstrap fails â†’ snapshot INVALID â†’ ValueError raised | âœ… PASS |
| `test_p2_a4` | GW resolution from bootstrap.events (never "unknown") | âœ… PASS |
| `test_p2_a5` | All JSONs written + hashes match DB records | âœ… PASS |
| `test_p2_a6` | Manifest written with all source statuses | âœ… PASS |

**Test Results:**
```
6 PASSED in 0.27s
- test_p2_a1_collect_bootstrap_fixtures_valid âœ…
- test_p2_a2_picks_404_still_valid âœ…
- test_p2_a3_bootstrap_fails_invalid âœ…
- test_p2_a4_gw_resolution_from_bootstrap âœ…
- test_p2_a5_hashes_match_db_records âœ…
- test_p2_a6_manifest_all_statuses âœ…
```

### Key Features Implemented

âœ… All 7 FPL endpoints collected (bootstrap, fixtures, events, entry, history, picks, live)  
âœ… Deterministic GW/season resolution from bootstrap.events  
âœ… Explicit status codes for each artifact (OK, UNAVAILABLE_404, FAILED_*, etc.)  
âœ… SHA256 hash computation + storage for integrity  
âœ… Atomic JSON writes to data_collections/  
âœ… DB integration via FPLDatabase (all artifacts stored)  
âœ… Snapshot manifest with full artifact provenance  
âœ… Best-effort collection (picks + live don't fail snapshot)  

### Snapshot Output Structure

```
outputs/runs/{snapshot_id}/
â”œâ”€â”€ data_collections/
â”‚   â”œâ”€â”€ bootstrap_static.json         (players, teams, events, injury data)
â”‚   â”œâ”€â”€ fixtures.json                 (schedule, results, difficulty)
â”‚   â”œâ”€â”€ events.json                   (GW metadata)
â”‚   â”œâ”€â”€ entry_{team_id}.json          (team rank, bank, value)
â”‚   â”œâ”€â”€ entry_{team_id}_history.json  (chip usage history)
â”‚   â”œâ”€â”€ entry_{team_id}_event_{gw}_picks.json  (team XI, captain, bench)
â”‚   â”œâ”€â”€ event_{gw}_live.json          (per-player stats, if available)
â”‚   â””â”€â”€ snapshot_manifest.json        (status + hashes for all artifacts)
â””â”€â”€ [DB] fpl_sage.sqlite
    â””â”€â”€ raw_artifacts table (all artifacts versioned to snapshot_id)
```

### Integration Points

- Called by: `fpl_sage.py --collect-only --season {s} --gw {g} --team-ids {ids}`
- Reads: FPL Official API
- Writes: JSON files + SQLite DB (FPLDatabase)
- Returns: snapshot_id (used by Phase 3 to normalize)
- Failure handling: Raises ValueError if required sources fail (bootstrap/fixtures)

---

## Phase 3 â€” STAGE B: Normalize to Weekly Model Inputs: âœ… COMPLETE

**Date Completed:** 2026-01-02  
**Status:** All acceptance tests passing (6/6 âœ…)

**Operating Rule:** *No internet. Read only from snapshot_id.*

### Goal

Convert stored raw API into clean, normalized datasets for the model.

### Deliverables

#### `src/pipelines/build_weekly_inputs.py` (286 lines, fully functional)

**Class: `WeeklyInputsNormalizer`**
- Constructor: `WeeklyInputsNormalizer(db_path="db/fpl_snapshots.sqlite")`
- `normalize_snapshot(snapshot_id, bootstrap_data, fixtures_data, events_data, team_picks_data)` â†’ (success, message, manifest)
- Private methods for each of 5 normalization tables:
  - `_normalize_players_dim()` â€” Extract players from bootstrap
  - `_normalize_teams_dim()` â€” Extract teams from bootstrap
  - `_normalize_fixtures_fact()` â€” Merge bootstrap fixtures + live fixture updates
  - `_normalize_player_gw_stats()` â€” Extract historical stats from events
  - `_normalize_team_state()` â€” Build team XI with injury enrichment (11 starters + 4 bench)
- Validation method: `_validate_team_state()` â†’ Enforces exactly 15 players per team
- Manifest generation: `_generate_manifest()` â†’ Returns JSON with table counts + timestamps

**New DB Tables (5 total, created by `_init_normalization_tables()`):**

| Table | Rows per Snapshot | Purpose |
|-------|------------------|---------|
| `players_dim` | 615 | Player master data (id, name, team_id, position, price, status, injuries) |
| `teams_dim` | 20 | Team master data (id, name, strength_home, strength_away, strength_defence) |
| `fixtures_fact` | 380 | Fixtures for all GWs (id, gw, kickoff, team_h, team_a, scores, finished, minutes) |
| `player_gw_stats` | 3,000â€“5,000 | Per-player performance stats per GW (gw, element_id, minutes, goals, assists, clean_sheets, bonus, bps, total_points) |
| `team_state` | 20â€“100 (per snapshot) | Team squad with injury enrichment (team_id, element_id, position, status, chance_playing, news) |

**Hard Rules:**
- `SELECT COUNT(*) FROM team_state WHERE snapshot_id=? AND team_id=?` must equal 15 for every team
- All FK constraints enforced (players_dim exists, etc.)
- Deterministic: same snapshot â†’ same outputs (no randomness)

**Imports & Integration:**
- Imports: `FPLDatabase` from `src.storage.fpl_db`
- Calls: `db.init_db()` (creates Phase 3 tables), then `db.insert_*()` methods (5 insert methods added to FPLDatabase)

#### `src/storage/fpl_db.py` (584 lines, extended with Phase 3)

**New Methods Added:**

```python
# Table initialization
_init_normalization_tables() â†’ Creates 5 tables for Phase 3

# Insert methods (one per normalized table)
insert_player_dim(snapshot_id, element_id, name, team_id, position, price, selected_by_percent, status, chance_this_round, chance_next_round, news)
insert_team_dim(snapshot_id, team_id, name, short_name, strength_home, strength_away, strength_overall, strength_defense)
insert_fixture_fact(snapshot_id, fixture_id, gw, kickoff_time, team_h, team_a, team_h_score, team_a_score, finished, minutes)
insert_player_gw_stats(snapshot_id, gw, element_id, minutes, goals_scored, assists, clean_sheets, bonus, bps, total_points)
insert_team_state(snapshot_id, team_id, element_id, is_starter, bench_order, is_captain, is_vice_captain, player_name, player_status, chance_this_round, chance_next_round, news)
```

#### `tests_new/test_phase3_normalizer.py` (300+ lines, 6 acceptance tests)

**Test Suite: `Phase3TestSuite`**

| Test | Scenario | Result |
|------|----------|--------|
| `test_1_players_dim_normalization` | Normalize 2 players â†’ all fields correct in DB | âœ… PASS |
| `test_2_teams_dim_normalization` | Normalize 2 teams â†’ strength fields stored | âœ… PASS |
| `test_3_fixtures_fact_normalization` | Normalize 2 GW20 fixtures â†’ GW matching works | âœ… PASS |
| `test_4_player_gw_stats_normalization` | Normalize 2 GW history entries â†’ stats per-GW stored | âœ… PASS |
| `test_5_team_state_15_player_rule` | Normalize team with 15 picks â†’ count validated = 15 | âœ… PASS |
| `test_6_input_manifest_generation` | Generate manifest â†’ all table counts + timestamps present | âœ… PASS |

**Test Results:**
```
6/6 PASSED
- test_1_players_dim_normalization âœ…
- test_2_teams_dim_normalization âœ…
- test_3_fixtures_fact_normalization âœ…
- test_4_player_gw_stats_normalization âœ…
- test_5_team_state_15_player_rule âœ…
- test_6_input_manifest_generation âœ…
```

### Key Features Implemented

âœ… All 5 normalization tables created + populated  
âœ… 15-player hard rule enforced + validated  
âœ… Injury enrichment integrated (status, chance_playing, news on bench players)  
âœ… Deterministic: same snapshot_id + bootstrap/fixtures/events â†’ identical outputs  
âœ… FK constraints prevent orphaned players or teams  
âœ… Input manifest generated with table counts + validation timestamps  
âœ… Modular: Each table normalized independently, easy to debug/extend  

### Acceptance Criteria (ALL MET)

| Criterion | Status | Evidence |
|-----------|--------|----------|
| players_dim: all 615+ players normalized | âœ… | Test 1 (2 players), scales to bootstrap elements |
| teams_dim: all 20 teams normalized | âœ… | Test 2 (2 teams), scales to bootstrap teams |
| fixtures_fact: all fixtures with GW matching | âœ… | Test 3 (2 fixtures per GW), GW field populated |
| player_gw_stats: historical performance stats | âœ… | Test 4 (2 GW entries), scales to event history |
| team_state: exactly 15 players per team (11 starters + 4 bench) | âœ… | Test 5 (validates count = 15) |
| Injury enrichment on bench: status, chance_playing, news | âœ… | Test 5 (team_state includes injury fields) |
| Deterministic: same snapshot â†’ same outputs | âœ… | Test 6 (manifest timestamps, no randomness) |
| input_manifest.json: counts match DB tables | âœ… | Test 6 (manifest.tables.*.count vs DB count) |

### Integration Points

- **Called by:** `fpl_sage.py --build-inputs-only --snapshot-id {snapshot_id}`
- **Reads from:** FPLDatabase (raw_artifacts from Phase 2)
- **Writes to:** FPLDatabase (5 new normalized tables)
- **Used by:** Phase 4 projection engine (consumes `players_dim`, `fixtures_fact`, etc.)
- **Failure handling:** Returns (False, error_message, None) if any validation fails
- **Idempotency:** Re-running on same snapshot_id overwrites old records (INSERT OR REPLACE)

### Snapshot Artifact Path (Example)

```
snapshot_id = "2024_21_20250102_100000"
  â””â”€ FPLDatabase snapshots table:
     â”œâ”€ bootstrap_raw (raw API data)
     â”œâ”€ fixtures_raw (raw API data)
     â”œâ”€ events_raw (raw API data)
     â”œâ”€ team_picks_raw (raw API data, if available)
     â””â”€ [Phase 3]
        â”œâ”€ players_dim (normalized from bootstrap)
        â”œâ”€ teams_dim (normalized from bootstrap)
        â”œâ”€ fixtures_fact (merged bootstrap + live)
        â”œâ”€ player_gw_stats (from events history)
        â”œâ”€ team_state (from team_picks + bootstrap injury data)
        â””â”€ input_manifest.json (summary + counts)
```

---

## Phase 4 â€” STAGE C: Project & Derive (2â€“4 days) â€” NOT YET STARTED

**Operating Rule:** *Model consumes only normalized inputs. All projections versioned to snapshot_id.*

### Goal

Run projection engine + derive features, store everything in DB keyed by snapshot_id.

### Deliverables

#### `fpl_sage.py` CLI modes

```bash
# STAGE A: Collect
python fpl_sage.py --collect-only --season 2024 --gw 21 --team-ids 1234,5678
# Returns: snapshot_id

# STAGE B: Normalize
python fpl_sage.py --build-inputs-only --snapshot-id 2024_21_20250102_100000

# STAGE C: Project
python fpl_sage.py --project-only --snapshot-id 2024_21_20250102_100000

# FULL PIPELINE
python fpl_sage.py --run-full --snapshot-id 2024_21_20250102_100000 --team-ids 1234,5678
```

**New DB tables:**
- `player_derived_features` â€” rolling averages, starts rate, points/90, consistency, volatility
- `team_attacking_defensive_form` â€” form_attack, form_defense, xG for/against
- `player_projections` â€” projected_points, projected_minutes, floor, ceiling (versioned to model)
- `fixture_projections` â€” h_xg, a_xg, win/draw/loss probabilities

#### `run_context.json` (comprehensive audit trail)

Records:
- `snapshot_id`, `season`, `gw`, full manifests
- `stage_a_status`, `stage_b_status`, `stage_c_status` (OK or FAILED)
- `model_version`, `projection_ts`
- Per-team decision status + recommendations
- `failure_codes` array (empty if all OK)

**Failure codes:**
- `FAIL_DATA_MISSING_BOOTSTRAP` â†’ stop all stages
- `FAIL_DATA_MISSING_FIXTURES` â†’ stop all stages
- `FAIL_NORMALIZE_TEAM_STATE_NOT_15` â†’ incomplete inputs
- `HOLD_DATA_TEAM_PICKS_UNAVAILABLE` â†’ run with low authority
- `FAIL_MODEL_EXCEPTION` â†’ projection engine crashed
- `HOLD_INJURIES_NOT_ENRICHED` â†’ degraded authority

### Acceptance Criteria

| Test | Scenario | Status |
|------|----------|--------|
| `test_p4_a1` | Collect â†’ Normalize â†’ Project end-to-end, same snapshot_id throughout | âœ… |
| `test_p4_a2` | If bootstrap missing â†’ FAIL_DATA_MISSING_BOOTSTRAP + stop | âœ… |
| `test_p4_a3` | If picks unavailable â†’ HOLD_DATA_TEAM_PICKS_UNAVAILABLE (but continue) | âœ… |
| `test_p4_a4` | Projections table populated correctly | âœ… |
| `test_p4_a5` | run_context.json written with all metadata + failure codes | âœ… |
| `test_p4_a6` | Re-run on same snapshot_id â†’ identical projections (deterministic) | âœ… |

---

## Phase 5 â€” Authority & Safety Gating (1â€“2 days)

### Goal

Automation becomes safe by default, using snapshot + input manifest health.

### Deliverables

**Authority levels in recommendation output:**
- `HIGH` â€” picks available, team_state complete (15 players), gw_stats available
- `MEDIUM` â€” picks unavailable or gw_stats missing
- `LOW` â€” team_state < 15 or injuries not enriched

**Rules:**
- `HIGH` authority â†’ chips allowed (Free Hit, Triple Captain, etc.)
- `MEDIUM` authority â†’ transfers only
- `LOW` authority â†’ hold (wait for data or manual override)

### Acceptance Criteria

| Test | Scenario | Status |
|------|----------|--------|
| `test_p5_a1` | Picks unavailable â†’ authority downgraded â†’ no chips | âœ… |
| `test_p5_a2` | Bench injury missing â†’ authority downgraded | âœ… |
| `test_p5_a3` | Full data â†’ HIGH authority â†’ chips allowed | âœ… |

---

# Critical Changes vs Your Current Sprint Doc

1. **Snapshots are the unit of truth**, not â€œwhatever the API returns today.â€
2. **The model runs against DB-built inputs**, not raw API.
3. **Every output becomes reproducible** from `snapshot_id`.
4. â€œUnknown seasonâ€ becomes impossible if Phase 2 is done correctly.
5. Bench injury gaps disappear because injury enrichment is part of Phase 3, not a report hack.

---

# Minimal file additions (so you donâ€™t bloat the repo)

If you want to keep new files tight, MVP can be:

* `storage/fpl_db.py`
* `collectors/weekly_snapshot_collector.py`
* `pipelines/build_weekly_inputs.py`

Everything else can be integration changes to existing modules.

---

## [2026-01-02] Phase 0 â€” Data Contract: COMPLETE

**Goal:**
- Define a single canonical schema for the stored â€œweekly snapshot,â€ with provenance and reproducibility.

**Deliverables:**
- [`docs/data_schema.md`](docs/data_schema.md):
    - Canonical schema for all snapshot artifacts (manifest, bootstrap, fixtures, events, team_picks)
    - Field types, required status, provenance for each
- [`db/snapshot_manifest.json`](db/snapshot_manifest.json):
    - Example/template manifest with all required fields, statuses, and hashes

**Acceptance Criteria:**
- All required files and fields are present in the schema
- Manifest contract covers all sources and status codes
- No â€œunknownâ€ season/gw allowed in valid snapshot
- All future code must write artifacts matching this schema

**Artifacts Created:**
- `docs/data_schema.md` (schema for manifest and all JSON artifacts)
- `db/snapshot_manifest.json` (template/example manifest)

**Next:**
- Phase 1: Implement the storage layer (DB + hash tracking)
