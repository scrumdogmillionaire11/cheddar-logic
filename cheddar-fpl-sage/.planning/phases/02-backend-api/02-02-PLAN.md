---
phase: 02-backend-api
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - backend/routers/__init__.py
  - backend/routers/analyze.py
  - backend/main.py
  - backend/services/engine_service.py
autonomous: true

must_haves:
  truths:
    - "POST /api/v1/analyze accepts team_id and returns analysis_id"
    - "GET /api/v1/analyze/{analysis_id} returns status and results"
    - "Invalid team_id returns 400 error with clear message"
    - "Analysis completes in under 15 seconds for typical team"
  artifacts:
    - path: "backend/routers/analyze.py"
      provides: "Analyze endpoints implementation"
      contains: "@router.post"
    - path: "backend/main.py"
      provides: "Router registration"
      contains: "include_router"
  key_links:
    - from: "backend/routers/analyze.py"
      to: "backend/services/engine_service.py"
      via: "engine_service import and method calls"
      pattern: "engine_service\\.(create_analysis|run_analysis|get_job)"
---

<objective>
Implement core analyze endpoints for triggering and polling analysis.

Purpose: Expose the decision engine via REST API so the frontend can trigger analysis and poll for results.

Output:
- POST /api/v1/analyze - trigger analysis, returns analysis_id
- GET /api/v1/analyze/{analysis_id} - get status and results
- Background task execution for analysis
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/02-backend-api/02-01-SUMMARY.md
@backend/services/engine_service.py
@backend/models/api_models.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create analyze router with POST endpoint</name>
  <files>
    backend/routers/__init__.py
    backend/routers/analyze.py
  </files>
  <action>
**Create backend/routers/__init__.py:**
```python
"""API Routers"""
from .analyze import router as analyze_router

__all__ = ["analyze_router"]
```

**Create backend/routers/analyze.py:**

```python
"""
Analyze endpoints for FPL Sage API.
Handles triggering analysis and retrieving results.
"""
from fastapi import APIRouter, BackgroundTasks, HTTPException, status
from typing import Optional
import logging

from backend.models.api_models import (
    AnalyzeRequest,
    AnalyzeResponse,
    AnalysisStatus,
    ErrorResponse,
)
from backend.services.engine_service import engine_service

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/analyze", tags=["analysis"])


@router.post(
    "",
    response_model=AnalyzeResponse,
    status_code=status.HTTP_202_ACCEPTED,
    responses={
        400: {"model": ErrorResponse, "description": "Invalid request"},
        429: {"model": ErrorResponse, "description": "Rate limited"},
    },
)
async def trigger_analysis(
    request: AnalyzeRequest,
    background_tasks: BackgroundTasks,
):
    """
    Trigger a new FPL analysis for the given team.

    - **team_id**: FPL team ID (required, 1-20000000 range)
    - **gameweek**: Target gameweek (optional, defaults to current)

    Returns an analysis_id that can be used to poll for results.
    """
    # Validate team_id range (FPL IDs are typically 1-20M)
    if request.team_id < 1 or request.team_id > 20_000_000:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail={
                "error": "Invalid team_id",
                "detail": f"team_id must be between 1 and 20000000, got {request.team_id}",
                "code": "INVALID_TEAM_ID",
            },
        )

    # Validate gameweek if provided
    if request.gameweek is not None:
        if request.gameweek < 1 or request.gameweek > 38:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail={
                    "error": "Invalid gameweek",
                    "detail": f"gameweek must be between 1 and 38, got {request.gameweek}",
                    "code": "INVALID_GAMEWEEK",
                },
            )

    # Create analysis job
    job = engine_service.create_analysis(request.team_id, request.gameweek)
    logger.info(f"Created analysis job {job.analysis_id} for team {request.team_id}")

    # Schedule background task
    background_tasks.add_task(run_analysis_task, job.analysis_id)

    return AnalyzeResponse(
        analysis_id=job.analysis_id,
        status="queued",
        created_at=job.created_at,
    )


async def run_analysis_task(analysis_id: str):
    """Background task to run the analysis."""
    try:
        await engine_service.run_analysis(analysis_id)
        logger.info(f"Analysis {analysis_id} completed successfully")
    except Exception as e:
        logger.exception(f"Analysis {analysis_id} failed: {e}")
        # Error is already recorded in the job by engine_service


@router.get(
    "/{analysis_id}",
    response_model=AnalysisStatus,
    responses={
        404: {"model": ErrorResponse, "description": "Analysis not found"},
    },
)
async def get_analysis_status(analysis_id: str):
    """
    Get the status and results of an analysis.

    - **analysis_id**: The ID returned from POST /analyze

    Returns status, progress percentage, and results when complete.
    """
    job = engine_service.get_job(analysis_id)

    if not job:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail={
                "error": "Analysis not found",
                "detail": f"No analysis found with ID: {analysis_id}",
                "code": "ANALYSIS_NOT_FOUND",
            },
        )

    return AnalysisStatus(
        status=job.status,
        progress=job.progress,
        phase=job.phase,
        results=job.results,
        error=job.error,
    )
```

Key design decisions:
- POST returns 202 Accepted (not 200) because work is queued
- Background task handles actual analysis
- Team ID validation (1-20M range matches FPL)
- Gameweek validation (1-38 for a season)
- Structured error responses with codes
  </action>
  <verify>
```bash
cd /Users/ajcolubiale/projects/cheddar-fpl-sage
python -m py_compile backend/routers/__init__.py
python -m py_compile backend/routers/analyze.py
```
  </verify>
  <done>
- backend/routers/analyze.py exists with POST and GET endpoints
- Input validation for team_id and gameweek
- Background task pattern for analysis execution
  </done>
</task>

<task type="auto">
  <name>Task 2: Register router in main app</name>
  <files>
    backend/main.py
  </files>
  <action>
**Update backend/main.py to include the analyze router:**

```python
"""
FPL Sage API - Main Application
"""
from contextlib import asynccontextmanager
from datetime import datetime, timezone
import logging

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

from backend.config import settings
from backend.routers import analyze_router

logging.basicConfig(level=logging.INFO if not settings.DEBUG else logging.DEBUG)
logger = logging.getLogger(__name__)


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan context manager."""
    logger.info("FPL Sage API starting up...")
    yield
    logger.info("FPL Sage API shutting down...")


app = FastAPI(
    title="FPL Sage API",
    description="AI-powered FPL decision engine API",
    version="1.0.0",
    lifespan=lifespan,
)

# CORS middleware - permissive for development
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Restrict in production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Include routers
app.include_router(analyze_router, prefix=settings.API_V1_PREFIX)


@app.get("/health")
async def health_check():
    """Health check endpoint."""
    return {
        "status": "healthy",
        "version": "1.0.0",
        "timestamp": datetime.now(timezone.utc).isoformat(),
    }


@app.get("/")
async def root():
    """Root endpoint with API info."""
    return {
        "name": "FPL Sage API",
        "version": "1.0.0",
        "docs": "/docs",
        "health": "/health",
    }
```
  </action>
  <verify>
```bash
cd /Users/ajcolubiale/projects/cheddar-fpl-sage
python -m py_compile backend/main.py

# Test that app can be imported
PYTHONPATH=src:backend python -c "
from backend.main import app
print(f'App title: {app.title}')
print(f'Routes: {[r.path for r in app.routes]}')
"
```
  </verify>
  <done>
- backend/main.py includes analyze_router
- API prefix is /api/v1
- Routes include /api/v1/analyze and /api/v1/analyze/{analysis_id}
  </done>
</task>

<task type="auto">
  <name>Task 3: Add API endpoint tests</name>
  <files>
    tests/tests_new/test_api_endpoints.py
  </files>
  <action>
**Create tests/tests_new/test_api_endpoints.py:**

```python
"""
Tests for FPL Sage API endpoints.
Uses FastAPI TestClient for synchronous testing.
"""
import pytest
from unittest.mock import patch, AsyncMock, MagicMock
from fastapi.testclient import TestClient
import sys
import os

# Add backend to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..', 'backend'))
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..', 'src'))

from backend.main import app


@pytest.fixture
def client():
    """Create test client."""
    return TestClient(app)


class TestHealthEndpoint:
    """Tests for /health endpoint."""

    def test_health_check_returns_200(self, client):
        """Health endpoint returns 200 with status healthy."""
        response = client.get("/health")
        assert response.status_code == 200
        data = response.json()
        assert data["status"] == "healthy"
        assert data["version"] == "1.0.0"
        assert "timestamp" in data

    def test_root_endpoint(self, client):
        """Root endpoint returns API info."""
        response = client.get("/")
        assert response.status_code == 200
        data = response.json()
        assert data["name"] == "FPL Sage API"


class TestAnalyzeEndpoint:
    """Tests for /api/v1/analyze endpoints."""

    def test_trigger_analysis_returns_202(self, client):
        """POST /analyze returns 202 with analysis_id."""
        response = client.post(
            "/api/v1/analyze",
            json={"team_id": 12345}
        )
        assert response.status_code == 202
        data = response.json()
        assert "analysis_id" in data
        assert data["status"] == "queued"
        assert "created_at" in data

    def test_trigger_analysis_with_gameweek(self, client):
        """POST /analyze accepts optional gameweek."""
        response = client.post(
            "/api/v1/analyze",
            json={"team_id": 12345, "gameweek": 25}
        )
        assert response.status_code == 202

    def test_invalid_team_id_zero(self, client):
        """POST /analyze rejects team_id of 0."""
        response = client.post(
            "/api/v1/analyze",
            json={"team_id": 0}
        )
        assert response.status_code == 400
        data = response.json()
        assert "INVALID_TEAM_ID" in str(data)

    def test_invalid_team_id_negative(self, client):
        """POST /analyze rejects negative team_id."""
        response = client.post(
            "/api/v1/analyze",
            json={"team_id": -1}
        )
        assert response.status_code == 400

    def test_invalid_team_id_too_large(self, client):
        """POST /analyze rejects team_id > 20M."""
        response = client.post(
            "/api/v1/analyze",
            json={"team_id": 25_000_000}
        )
        assert response.status_code == 400

    def test_invalid_gameweek_zero(self, client):
        """POST /analyze rejects gameweek of 0."""
        response = client.post(
            "/api/v1/analyze",
            json={"team_id": 12345, "gameweek": 0}
        )
        assert response.status_code == 400
        data = response.json()
        assert "INVALID_GAMEWEEK" in str(data)

    def test_invalid_gameweek_too_large(self, client):
        """POST /analyze rejects gameweek > 38."""
        response = client.post(
            "/api/v1/analyze",
            json={"team_id": 12345, "gameweek": 40}
        )
        assert response.status_code == 400

    def test_get_analysis_status(self, client):
        """GET /analyze/{id} returns status for existing job."""
        # First create an analysis
        create_response = client.post(
            "/api/v1/analyze",
            json={"team_id": 12345}
        )
        analysis_id = create_response.json()["analysis_id"]

        # Then get its status
        response = client.get(f"/api/v1/analyze/{analysis_id}")
        assert response.status_code == 200
        data = response.json()
        assert "status" in data
        assert data["status"] in ["queued", "running", "completed", "failed"]

    def test_get_analysis_not_found(self, client):
        """GET /analyze/{id} returns 404 for unknown job."""
        response = client.get("/api/v1/analyze/nonexistent123")
        assert response.status_code == 404
        data = response.json()
        assert "ANALYSIS_NOT_FOUND" in str(data)

    def test_missing_team_id(self, client):
        """POST /analyze requires team_id."""
        response = client.post(
            "/api/v1/analyze",
            json={}
        )
        assert response.status_code == 422  # Pydantic validation error
```

Note: These tests use TestClient which handles async endpoints synchronously. The actual analysis won't run in tests (background task), but we verify the API contract.
  </action>
  <verify>
```bash
cd /Users/ajcolubiale/projects/cheddar-fpl-sage

# Install test dependencies if needed
pip install httpx --quiet

# Run API tests
PYTHONPATH=src:backend python -m pytest tests/tests_new/test_api_endpoints.py -v
```
  </verify>
  <done>
- test_api_endpoints.py has 12+ test cases
- Tests cover: health check, POST /analyze validation, GET /analyze status
- All tests pass
  </done>
</task>

</tasks>

<verification>
After all tasks complete:

```bash
cd /Users/ajcolubiale/projects/cheddar-fpl-sage

# 1. Verify router structure
ls -la backend/routers/

# 2. Test imports
PYTHONPATH=src:backend python -c "
from backend.main import app
from backend.routers.analyze import router
print('Router paths:', [r.path for r in router.routes])
"

# 3. Run all API tests
PYTHONPATH=src:backend python -m pytest tests/tests_new/test_api_endpoints.py -v

# 4. Quick manual test with uvicorn (optional)
# PYTHONPATH=src:backend uvicorn backend.main:app --reload --port 8000
# Then visit http://localhost:8000/docs
```
</verification>

<success_criteria>
- POST /api/v1/analyze returns 202 with analysis_id
- GET /api/v1/analyze/{id} returns job status
- Input validation rejects invalid team_id and gameweek
- 12+ API tests pass
- API documentation available at /docs
</success_criteria>

<output>
After completion, create `.planning/phases/02-backend-api/02-02-SUMMARY.md`
</output>
