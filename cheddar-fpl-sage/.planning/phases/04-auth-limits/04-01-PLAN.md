---
phase: 04-auth-limits
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/services/usage_service.py
  - backend/routers/usage.py
  - backend/main.py
  - backend/routers/analyze.py
autonomous: true

must_haves:
  truths:
    - "Backend tracks analysis count per team_id per gameweek"
    - "Backend blocks analysis requests when limit (2/GW) reached"
    - "Backend exposes usage data via API endpoint"
    - "Usage resets when gameweek changes"
    - "Different team_ids have independent quotas"
  artifacts:
    - path: "backend/services/usage_service.py"
      provides: "Usage tracking and limit enforcement"
      min_lines: 80
      exports: ["UsageService", "usage_service"]
    - path: "backend/routers/usage.py"
      provides: "Usage API endpoint"
      exports: ["router"]
    - path: "backend/routers/analyze.py"
      provides: "Updated analyze endpoint with usage checks"
      contains: "usage_service"
  key_links:
    - from: "backend/services/usage_service.py"
      to: "redis"
      via: "Redis sorted sets for usage tracking"
      pattern: "zadd.*fpl_sage:usage"
    - from: "backend/routers/analyze.py"
      to: "backend/services/usage_service.py"
      via: "Check limit before creating analysis"
      pattern: "usage_service\\.check_limit"
    - from: "backend/routers/usage.py"
      to: "backend/services/usage_service.py"
      via: "Expose usage data to frontend"
      pattern: "usage_service\\.get_usage"
---

<objective>
Implement backend usage tracking and enforcement for freemium limits. Track analyses per FPL Team ID, enforce 2 analyses per gameweek, and expose usage data via API.

Purpose: Enable freemium business model by limiting free tier usage while maintaining clear, transparent enforcement.

Output: Working usage tracking system that blocks analysis requests at limit and provides usage data to frontend.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-auth-limits/04-CONTEXT.md

# Existing backend infrastructure
@backend/main.py
@backend/services/cache_service.py
@backend/routers/analyze.py
@backend/middleware/rate_limit.py
@backend/config.py
</context>

<tasks>

<task type="auto">
  <name>Create usage tracking service</name>
  <files>backend/services/usage_service.py</files>
  <action>
Create `UsageService` class that tracks and enforces analysis limits per team_id per gameweek.

**Key requirements:**
- Track using Redis sorted sets (similar pattern to rate_limit.py)
- Key format: `fpl_sage:usage:{team_id}:{gameweek}`
- Store completion timestamps as sorted set members
- Detect current gameweek from FPL API bootstrap-static endpoint (current_event field)
- Fallback: If FPL API unavailable, use cached gameweek or allow (graceful degradation)

**Methods:**
1. `get_current_gameweek() -> int` - Fetch from FPL API bootstrap-static, cache for 1 hour
2. `check_limit(team_id: int) -> Tuple[bool, int, int]` - Returns (allowed, used, limit, gw_reset_time)
3. `record_analysis(team_id: int, gameweek: int) -> None` - Increment usage count
4. `get_usage(team_id: int) -> Dict[str, Any]` - Get usage stats for frontend display

**Implementation details:**
- Use Redis pipeline for atomic operations (see rate_limit.py pattern)
- Set TTL on usage keys: 2 weeks (covers gameweek lifecycle)
- Limit: 2 analyses per gameweek per team_id
- Count only successful completions (call record_analysis AFTER analysis completes)
- Store timestamps for potential future features (usage history)

**Graceful degradation:**
- If Redis unavailable: log warning, allow analysis (same pattern as cache_service.py)
- If FPL API unavailable: use last known gameweek from cache, or allow with warning

**Why not use existing rate_limit middleware:** Rate limiting is per-IP per-hour (prevents abuse). Usage limits are per-team_id per-gameweek (freemium business logic). Separate concerns.

Create singleton instance: `usage_service = UsageService()`
  </action>
  <verify>
```bash
# Service exists and has required methods
python3 -c "from backend.services.usage_service import usage_service; print(dir(usage_service))"

# Run backend tests if they exist
pytest backend/tests/ -k usage -v || echo "Tests pending"
```
  </verify>
  <done>
- UsageService class exists with all 4 methods
- Uses Redis with key pattern `fpl_sage:usage:{team_id}:{gw}`
- Fetches current gameweek from FPL API
- Gracefully degrades when Redis/API unavailable
- Singleton instance exported
  </done>
</task>

<task type="auto">
  <name>Add usage enforcement to analyze endpoint</name>
  <files>backend/routers/analyze.py</files>
  <action>
Integrate usage_service into the analyze endpoint to enforce limits BEFORE creating analysis jobs.

**Changes to `trigger_analysis` function:**

1. Import usage_service at top:
```python
from backend.services.usage_service import usage_service
```

2. Add usage check AFTER team_id validation, BEFORE cache check:
```python
# Check usage limit
allowed, used, limit, reset_time = usage_service.check_limit(request.team_id)
if not allowed:
    raise HTTPException(
        status_code=status.HTTP_403_FORBIDDEN,
        detail={
            "error": "Usage limit reached",
            "detail": f"You've used {used} of {limit} free analyses this gameweek",
            "code": "USAGE_LIMIT_REACHED",
            "used": used,
            "limit": limit,
            "reset_time": reset_time,
        },
    )
```

3. Add usage recording AFTER successful analysis (in `run_analysis_task`):
```python
# In run_analysis_task, after results = await engine_service.run_analysis(...)
# Record successful analysis
current_gw = usage_service.get_current_gameweek()
usage_service.record_analysis(team_id, current_gw)
logger.info(f"Recorded analysis for team {team_id} in GW {current_gw}")
```

**Why record in background task, not in trigger_analysis:** Only count successful completions, not queued/failed attempts. This prevents users being charged for errors.

**Testing strategy:**
- First analysis: allowed, used=0
- Second analysis: allowed, used=1
- Third analysis: blocked with 403, detail includes reset_time
  </action>
  <verify>
```bash
# Check imports added
grep "usage_service" backend/routers/analyze.py

# Verify 403 response structure
grep -A 5 "USAGE_LIMIT_REACHED" backend/routers/analyze.py

# Run analyze endpoint tests
pytest backend/tests/ -k analyze -v || echo "Tests pending"
```
  </verify>
  <done>
- trigger_analysis checks usage_service.check_limit() before creating job
- Returns 403 with usage details when limit reached
- run_analysis_task records successful completions
- Error response includes used, limit, reset_time for UI display
  </done>
</task>

<task type="auto">
  <name>Create usage API endpoint and register</name>
  <files>backend/routers/usage.py, backend/main.py</files>
  <action>
Create new router exposing usage data for frontend consumption.

**File: backend/routers/usage.py**

```python
"""
Usage tracking endpoints for freemium limits.
"""
from fastapi import APIRouter, HTTPException, status
from pydantic import BaseModel
import logging

from backend.services.usage_service import usage_service

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/usage", tags=["usage"])


class UsageResponse(BaseModel):
    """Usage statistics for a team."""
    team_id: int
    gameweek: int
    used: int
    limit: int
    remaining: int
    reset_time: int  # Unix timestamp


@router.get("/{team_id}", response_model=UsageResponse)
async def get_team_usage(team_id: int):
    """
    Get usage statistics for a team in the current gameweek.

    Returns:
    - used: Number of analyses completed this GW
    - limit: Maximum analyses allowed per GW
    - remaining: Analyses remaining (limit - used)
    - reset_time: Unix timestamp when GW resets
    """
    # Validate team_id range
    if team_id < 1 or team_id > 20_000_000:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail={
                "error": "Invalid team_id",
                "detail": f"team_id must be between 1 and 20000000",
                "code": "INVALID_TEAM_ID",
            },
        )

    usage_data = usage_service.get_usage(team_id)

    return UsageResponse(
        team_id=team_id,
        gameweek=usage_data["gameweek"],
        used=usage_data["used"],
        limit=usage_data["limit"],
        remaining=max(0, usage_data["limit"] - usage_data["used"]),
        reset_time=usage_data["reset_time"],
    )
```

**File: backend/main.py** - Register router

Add import:
```python
from backend.routers import analyze_router, usage_router
```

Wait, check the routers/__init__.py structure first. If it exports routers, import from there. Otherwise import directly:
```python
from backend.routers.usage import router as usage_router
```

Add registration after analyze_router:
```python
app.include_router(usage_router, prefix=settings.API_V1_PREFIX)
```

**Endpoint behavior:**
- GET /api/v1/usage/711511 â†’ returns current usage for team 711511
- Used by frontend Landing page to display "X of 2 analyses used"
- Always returns current gameweek data (not historical)
  </action>
  <verify>
```bash
# Check router created
test -f backend/routers/usage.py && echo "Router exists"

# Check registered in main.py
grep "usage_router" backend/main.py

# Test endpoint (if backend running)
# curl http://localhost:8000/api/v1/usage/711511 | jq

# Check OpenAPI docs include new endpoint
grep -i "usage" backend/main.py || echo "Check /docs after backend starts"
```
  </verify>
  <done>
- backend/routers/usage.py created with GET /{team_id} endpoint
- UsageResponse model includes used, limit, remaining, reset_time
- Router registered in main.py
- Endpoint validates team_id range (1-20M)
- Returns current gameweek usage data
  </done>
</task>

</tasks>

<verification>
**Manual verification steps:**

1. **Start backend with Redis:**
```bash
cd backend
redis-server &  # If not running
uvicorn backend.main:app --reload
```

2. **Test usage tracking:**
```bash
# First analysis (should succeed)
curl -X POST http://localhost:8000/api/v1/analyze \
  -H "Content-Type: application/json" \
  -d '{"team_id": 711511}'

# Check usage
curl http://localhost:8000/api/v1/usage/711511

# Second analysis (should succeed)
curl -X POST http://localhost:8000/api/v1/analyze \
  -H "Content-Type: application/json" \
  -d '{"team_id": 711511}'

# Third analysis (should return 403)
curl -X POST http://localhost:8000/api/v1/analyze \
  -H "Content-Type: application/json" \
  -d '{"team_id": 711511}'
# Expect: {"error": "Usage limit reached", "code": "USAGE_LIMIT_REACHED", "used": 2, "limit": 2}

# Different team_id (should succeed - independent quota)
curl -X POST http://localhost:8000/api/v1/analyze \
  -H "Content-Type: application/json" \
  -d '{"team_id": 999999}'
```

3. **Verify graceful degradation:**
```bash
# Stop Redis
redis-cli shutdown

# Try analysis (should succeed with warning in logs)
curl -X POST http://localhost:8000/api/v1/analyze \
  -H "Content-Type: application/json" \
  -d '{"team_id": 711511}'
# Check logs for "Running without usage tracking" warning
```

4. **Verify OpenAPI docs:**
- Visit http://localhost:8000/docs
- Check GET /api/v1/usage/{team_id} endpoint exists
- Check POST /api/v1/analyze returns 403 response schema

</verification>

<success_criteria>
**Backend usage tracking complete when:**
- [ ] UsageService tracks analyses per team_id per gameweek using Redis
- [ ] Fetches current gameweek from FPL API with hourly cache
- [ ] Analyze endpoint checks limit before creating job (returns 403 at limit)
- [ ] Analyze endpoint records successful completions (not attempts)
- [ ] GET /api/v1/usage/{team_id} returns usage stats
- [ ] Different team_ids have independent quotas
- [ ] Gracefully degrades when Redis unavailable (allows with warning)
- [ ] Manual curl tests confirm: 1st analysis OK, 2nd OK, 3rd blocked
- [ ] OpenAPI docs show new endpoint and 403 response
</success_criteria>

<output>
After completion, create `.planning/phases/04-auth-limits/04-01-SUMMARY.md` following the summary template.

Include:
- Usage service implementation details (Redis key structure, TTL)
- Gameweek detection mechanism (FPL API endpoint used)
- Error response format for limit reached
- Graceful degradation behavior
- Test commands used for verification
</output>
